{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Project: Song Recommendation System Based on User Mood\n",
    "This project aims to create a system that suggests songs based on a user's mood. We will use Spotify and Genius APIs to fetch user data, process this data to create embeddings using a pre-trained transformer model, store these embeddings in a FAISS index, and use LangChain and MLflow to manage the retrieval and generation processes.\n",
    " Step-by-Step Guide\n",
    " \n",
    " 1. Setup Environment and Install Dependencies\n",
    "**Why:** To ensure all necessary packages and tools are available for the project.\n",
    "**Action:** Install the required libraries such as `lyricsgenius`, `spotipy`, `transformers`, `scikit-learn`, `faiss-cpu`, `tqdm`, and `mlflow`.\n",
    "**Commands:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lyricsgenius in /Users/paniz/anaconda3/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from lyricsgenius) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from lyricsgenius) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (1.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spotipy in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.24.0)\n",
      "Requirement already satisfied: redis>=3.5.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (5.0.8)\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (1.26.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spotipy in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.24.0)\n",
      "Requirement already satisfied: lyricsgenius in /Users/paniz/anaconda3/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers in /Users/paniz/anaconda3/lib/python3.11/site-packages (4.39.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/paniz/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: gtts in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.5.2)\n",
      "Requirement already satisfied: pydub in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: librosa in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: redis>=3.5.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (5.0.8)\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (1.26.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from lyricsgenius) (4.12.3)\n",
      "Requirement already satisfied: filelock in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from gtts) (8.0.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/paniz/.local/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.5.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/paniz/.local/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/paniz/anaconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faiss-cpu in /Users/paniz/anaconda3/lib/python3.11/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (1.24.4)\n",
      "Requirement already satisfied: packaging in /Users/paniz/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /Users/paniz/anaconda3/lib/python3.11/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lyricsgenius\n",
    "%pip install spotipy\n",
    "%pip install spotipy lyricsgenius transformers scikit-learn gtts pydub librosa\n",
    "%pip install faiss-cpu\n",
    "%pip install tqdm\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# data = pd.read_csv(\"spotify/data/data.csv\")\n",
    "# genre_data = pd.read_csv('spotify/data/data_by_genres.csv')\n",
    "# year_data = pd.read_csv('spotify/data/data_by_year.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import tqdm \n",
    "\n",
    "# # show stahe of the progress bar\n",
    "# tqdm.tqdm.pandas()\n",
    "\n",
    "# # Setting the base directory using list of directory names\n",
    "# base_dir = \"data\"\n",
    "\n",
    "# # Building paths by further extending the base directory\n",
    "# data_path = os.path.join(base_dir, \"data.csv\")\n",
    "# genre_data_path = os.path.join(base_dir, \"data_by_genres.csv\")\n",
    "# year_data_path = os.path.join(base_dir, \"data_by_year.csv\")\n",
    "\n",
    "# # Reading the data using pandas\n",
    "# data = pd.read_csv(data_path)\n",
    "# genre_data = pd.read_csv(genre_data_path)\n",
    "# year_data = pd.read_csv(year_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spotify \n",
    "\n",
    "\n",
    "# import spotipy\n",
    "# client_id = '10cc8ee290404da9ab9d7b061d526193'\n",
    "# client_secret = '0dc9cb56d8bc4454afa1ddbe82a7301d'\n",
    "\n",
    "# tqdm.tqdm.pandas()\n",
    "\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "# client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "# sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# # check health \n",
    "# sp.trace = False\n",
    "# track = sp.track('7qiZfU4dY1lWllzX7mPBI3')\n",
    "# print(track['name'])\n",
    "# # Now you have the access token to make requests to the Spotify API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # login to spotfy account as user and get their playlists\n",
    "# import spotipy.util as util\n",
    "\n",
    "# username = 'eqanbww3jh63cgf4ot5zyyr5d'\n",
    "# scope = 'playlist-read-private'\n",
    "# token = util.prompt_for_user_token(username, scope, client_id, client_secret, redirect_uri='http://localhost:8888/callback')\n",
    "# if token:\n",
    "#     sp = spotipy.Spotify(auth=token)\n",
    "#     playlists = sp.user_playlists(username)\n",
    "#     for playlist in playlists['items']:\n",
    "#         print(playlist['name'])\n",
    "\n",
    "# else:\n",
    "#     print(\"Can't get token for\", username)\n",
    "\n",
    "# # list songs in all the playlist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lyricsgenius in /Users/paniz/anaconda3/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: spotipy in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.24.0)\n",
      "Requirement already satisfied: transformers in /Users/paniz/anaconda3/lib/python3.11/site-packages (4.39.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/paniz/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: gtts in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.5.2)\n",
      "Requirement already satisfied: pydub in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: librosa in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/paniz/anaconda3/lib/python3.11/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: tqdm in /Users/paniz/anaconda3/lib/python3.11/site-packages (4.66.4)\n",
      "Requirement already satisfied: mlflow in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.15.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from lyricsgenius) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from lyricsgenius) (2.32.3)\n",
      "Requirement already satisfied: redis>=3.5.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (5.0.8)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from spotipy) (1.26.0)\n",
      "Requirement already satisfied: filelock in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from gtts) (8.0.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/paniz/.local/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.15.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (2.15.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (1.13.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (3.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (3.9.0)\n",
      "Requirement already satisfied: pandas<3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (2.0.3)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: querystring-parser<2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (2.0.30)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<23 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow) (22.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (5.4.0)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.29.0)\n",
      "Requirement already satisfied: entrypoints<1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (6.0.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (5.27.0)\n",
      "Requirement already satisfied: pytz<2025 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.5.1)\n",
      "Requirement already satisfied: Mako in /Users/paniz/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.4)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (2.0.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/paniz/.local/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: six in /Users/paniz/.local/lib/python3.11/site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->lyricsgenius) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/paniz/anaconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (2.33.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.15.1->mlflow) (3.11.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (0.47b0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /Users/paniz/anaconda3/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up Spotify API...\n",
      "INFO:__main__:Setting up Genius API...\n",
      "INFO:__main__:Loading pre-trained transformer model...\n",
      "INFO:__main__:Fetching and processing data...\n",
      "INFO:__main__:Fetching top 5 tracks from Spotify...\n",
      "INFO:__main__:Fetched 5 tracks.\n",
      "INFO:__main__:Fetching audio features from Spotify...\n",
      "INFO:__main__:Fetched audio features for 5 tracks.\n",
      "INFO:__main__:Fetching user playlists from Spotify...\n",
      "INFO:__main__:Fetched 49 playlists.\n",
      "INFO:__main__:Fetching lyrics for Lucky Strike by Maroon 5 from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Lucky Strike\" by Maroon 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Lucky Strike.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching lyrics for Love Me by Lil Wayne from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Love Me\" by Lil Wayne...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Love Me.\n",
      "INFO:__main__:Memory usage: 918.41 MB\n",
      "INFO:__main__:Fetching lyrics for DO IT AGAIN (feat. 2Rare) by NLE Choppa from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"DO IT AGAIN (feat. 2Rare)\" by NLE Choppa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for DO IT AGAIN (feat. 2Rare).\n",
      "INFO:__main__:Fetching lyrics for Tell Em by Cochise from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"Tell Em\" by Cochise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Tell Em.\n",
      "INFO:__main__:Memory usage: 963.02 MB\n",
      "INFO:__main__:Fetching lyrics for Koi Si by Afsana Khan from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"Koi Si\" by Afsana Khan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Koi Si.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory usage: 978.39 MB\n",
      "INFO:__main__:Creating FAISS index with dimension 768...\n",
      "INFO:__main__:FAISS index created.\n",
      "INFO:__main__:Memory usage: 978.47 MB\n",
      "INFO:__main__:Creating FAISS index with dimension 8...\n",
      "INFO:__main__:FAISS index created.\n",
      "INFO:__main__:Memory usage: 978.47 MB\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for the project\n",
    "# This ensures all necessary packages are available for audio processing, text embedding, API interactions, and data management\n",
    "%pip install lyricsgenius spotipy transformers scikit-learn gtts pydub librosa faiss-cpu tqdm mlflow\n",
    "%pip install torch  --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Import essential libraries for the project\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import lyricsgenius\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import logging\n",
    "import psutil  # For monitoring system memory\n",
    "import gc  # For managing memory through garbage collection\n",
    "\n",
    "# Set up logging to monitor and log the flow of execution and potential issues\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "SPOTIFY_CLIENT_ID = '***REMOVED***'\n",
    "SPOTIFY_CLIENT_SECRET = '***REMOVED***'\n",
    "SPOTIFY_REDIRECT_URI = 'http://localhost:8888/callback'\n",
    "GENIUS_API_TOKEN = '***REMOVED***'\n",
    "\n",
    "\n",
    "# Initialize the Spotify API with user credentials for accessing music-related data\n",
    "logger.info(\"Setting up Spotify API...\")\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=SPOTIFY_CLIENT_ID,\n",
    "                                               client_secret=SPOTIFY_CLIENT_SECRET,\n",
    "                                               redirect_uri=SPOTIFY_REDIRECT_URI,\n",
    "                                               scope=\"user-top-read user-library-read playlist-read-private\"))\n",
    "\n",
    "# Initialize the Genius API with your credentials to fetch song lyrics\n",
    "logger.info(\"Setting up Genius API...\")\n",
    "genius = lyricsgenius.Genius(GENIUS_API_TOKEN)\n",
    "\n",
    "# Load a pre-trained transformer model and tokenizer for processing lyrics into embeddings\n",
    "logger.info(\"Loading pre-trained transformer model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Ensure the model operates on CPU to prevent GPU memory overflow issues\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define a function to embed textual data using the transformer model to get fixed-size numerical vectors\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "# Function to monitor and log the memory usage to manage resources efficiently\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    logger.info(f\"Memory usage: {mem_info.rss / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "# Retrieve and log the user's most listened tracks from Spotify\n",
    "def get_spotify_top_tracks(sp, limit=5, time_range='medium_term'):\n",
    "    logger.info(f\"Fetching top {limit} tracks from Spotify...\")\n",
    "    results = sp.current_user_top_tracks(limit=limit, time_range=time_range)\n",
    "    tracks = results['items']\n",
    "    logger.info(f\"Fetched {len(tracks)} tracks.\")\n",
    "    return tracks\n",
    "\n",
    "# Fetch and log playlists created by the user on Spotify\n",
    "def get_spotify_playlists(sp):\n",
    "    logger.info(\"Fetching user playlists from Spotify...\")\n",
    "    results = sp.current_user_playlists()\n",
    "    playlists = results['items']\n",
    "    logger.info(f\"Fetched {len(playlists)} playlists.\")\n",
    "    return playlists\n",
    "\n",
    "# Fetch and log the audio features of tracks from Spotify which includes metrics like tempo, energy, etc.\n",
    "def get_audio_features(sp, track_ids):\n",
    "    logger.info(\"Fetching audio features from Spotify...\")\n",
    "    audio_features = sp.audio_features(track_ids)\n",
    "    logger.info(f\"Fetched audio features for {len(audio_features)} tracks.\")\n",
    "    return audio_features\n",
    "\n",
    "# Retrieve and log lyrics for specified songs using the Genius API\n",
    "def get_lyrics(artist, title):\n",
    "    logger.info(f\"Fetching lyrics for {title} by {artist} from Genius...\")\n",
    "    song = genius.search_song(title, artist)\n",
    "    if song:\n",
    "        logger.info(f\"Fetched lyrics for {title}.\")\n",
    "        return song.lyrics\n",
    "    logger.warning(f\"Lyrics for {title} by {artist} not found.\")\n",
    "    return None\n",
    "\n",
    "# Convert audio features into a numerical vector for processing and comparison\n",
    "def audio_features_to_vector(audio_features):\n",
    "    vector = np.array([\n",
    "        audio_features['danceability'],\n",
    "        audio_features['energy'],\n",
    "        audio_features['speechiness'],\n",
    "        audio_features['acousticness'],\n",
    "        audio_features['instrumentalness'],\n",
    "        audio_features['liveness'],\n",
    "        audio_features['valence'],\n",
    "        audio_features['tempo']\n",
    "    ])\n",
    "    return vector\n",
    "\n",
    "# Create and log a FAISS index for efficient similarity searches among large datasets\n",
    "def create_faiss_index(data, dimension):\n",
    "    logger.info(f\"Creating FAISS index with dimension {dimension}...\")\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(data)\n",
    "    logger.info(\"FAISS index created.\")\n",
    "    log_memory_usage()\n",
    "    return index\n",
    "\n",
    "# Batch processing to manage memory usage while fetching and processing data from Spotify\n",
    "def fetch_and_process_data(sp, limit=5, batch_size=2):\n",
    "    tracks = get_spotify_top_tracks(sp, limit=limit)\n",
    "    track_ids = [track['id'] for track in tracks]\n",
    "    audio_features = get_audio_features(sp, track_ids)\n",
    "    \n",
    "    playlists = get_spotify_playlists(sp)\n",
    "    playlist_names = [playlist['name'] for playlist in playlists]\n",
    "    \n",
    "    lyrics_data = []\n",
    "    audio_vectors = []\n",
    "    \n",
    "    for i in range(0, len(tracks), batch_size):\n",
    "        batch_tracks = tracks[i:i+batch_size]\n",
    "        batch_audio_features = audio_features[i:i+batch_size]\n",
    "        \n",
    "        for track, audio_feature in zip(batch_tracks, batch_audio_features):\n",
    "            artist = track['artists'][0]['name']\n",
    "            title = track['name']\n",
    "            lyrics = get_lyrics(artist, title)\n",
    "            if lyrics:\n",
    "                lyrics_embedding = embed_text(lyrics)\n",
    "                audio_vector = audio_features_to_vector(audio_feature)\n",
    "                lyrics_data.append({'id': track['id'], 'embedding': lyrics_embedding, 'artist': artist, 'title': title, 'lyrics': lyrics})\n",
    "                audio_vectors.append(audio_vector)\n",
    "        \n",
    "        # Release memory after processing each batch\n",
    "        del batch_tracks, batch_audio_features\n",
    "        gc.collect()\n",
    "        log_memory_usage()\n",
    "    \n",
    "    lyrics_embeddings = np.vstack([song['embedding'] for song in lyrics_data])\n",
    "    audio_vectors = np.vstack(audio_vectors)\n",
    "    \n",
    "    return lyrics_data, lyrics_embeddings, audio_vectors, playlist_names\n",
    "\n",
    "# Execute the data fetching and processing\n",
    "logger.info(\"Fetching and processing data...\")\n",
    "lyrics_data, lyrics_embeddings, audio_vectors, playlist_names = fetch_and_process_data(sp, limit=5)\n",
    "\n",
    "# Create indices for the embeddings and vectors to facilitate efficient similarity searches\n",
    "lyrics_index = create_faiss_index(lyrics_embeddings, 768)\n",
    "audio_index = create_faiss_index(audio_vectors, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-community in /Users/paniz/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.71)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/paniz/anaconda3/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: requests in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/paniz/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community\n",
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: distilbert-base-uncased\n",
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "def embed_user_query(user_input):\n",
    "    logger.info(\"Embedding user query using LangChain...\")\n",
    "    user_embedding = embeddings.embed_query(user_input)\n",
    "    logger.info(\"User query embedded.\")\n",
    "    user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "    print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "    return user_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 5\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "\n",
    "def retrieve_lyrics_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "    docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "    return docs\n",
    "\n",
    "def retrieve_audio_features_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing audio feature retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=audio_index)\n",
    "    docs = retriever.similarity_search(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 audio features using LangChain.\")\n",
    "    return docs\n",
    "    \n",
    "def combine_retrieval_results(lyrics_docs, audio_docs):\n",
    "    logger.info(\"Combining retrieval results...\")\n",
    "    combined_results = lyrics_docs + audio_docs  # This could be a simple concatenation or more sophisticated merging\n",
    "    logger.info(f\"Combined {len(combined_results)} results.\")\n",
    "    return combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use the above in the cell w retrieve lyrics w langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19551823b4fa4125be97514fad47a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9500e629d0a4a299a39f6834e9a5426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b817cea1f8814f7db7925a7203375540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aadbe2ec0f34f9e82b7bef2a863b040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdfeaeea2da43e09d477e6af5b53133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be77f4acba3a42dabde8c5559a3dd6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c6b9f35e4c4e988b0a96b6ab0cd3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 6\n",
    "def format_recommendations(retrieved_docs):\n",
    "    logger.info(\"Formatting recommendations...\")\n",
    "    formatted_response = \"\\n\".join([f\"Song: {doc.metadata['title']} by {doc.metadata['artist']}\\n{doc.page_content[:100]}...\" for doc in retrieved_docs])\n",
    "    logger.info(\"Recommendations formatted.\")\n",
    "    return formatted_response\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the generation pipeline using an open-source model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "def generate_personalized_response(formatted_recommendations, user_query):\n",
    "    logger.info(\"Generating personalized response using LangChain...\")\n",
    "    response = generator(f\"Context: {formatted_recommendations}\\n\\nQuestion: {user_query}\\nAnswer:\", max_length=200, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: distilbert-base-uncased\n",
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with mean pooling.\n",
      "INFO:__main__:Embedding user query using LangChain...\n",
      "INFO:__main__:User query embedded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User embedding shape: (768,)\n",
      "Query embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "#testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: distilbert-base-uncased\n",
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with mean pooling.\n",
      "INFO:__main__:Embedding user query using LangChain...\n",
      "INFO:__main__:User query embedded.\n",
      "INFO:__main__:Performing lyrics retrieval using LangChain...\n",
      "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User embedding shape: (768,)\n",
      "Query embedding shape: (768,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved top 5 lyrics using LangChain.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[0;32m---> 48\u001b[0m lyrics_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_lyrics_with_langchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Check the results\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLyrics retrieval results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 43\u001b[0m, in \u001b[0;36mretrieve_lyrics_with_langchain\u001b[0;34m(query_embedding)\u001b[0m\n\u001b[1;32m     41\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming lyrics retrieval using LangChain...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m retriever \u001b[38;5;241m=\u001b[39m FAISS(embedding_function\u001b[38;5;241m=\u001b[39membeddings\u001b[38;5;241m.\u001b[39membed_query, index\u001b[38;5;241m=\u001b[39mlyrics_index, docstore\u001b[38;5;241m=\u001b[39mInMemoryDocstore(lyrics_data), index_to_docstore_id\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m---> 43\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved top 5 lyrics using LangChain.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:469\u001b[0m, in \u001b[0;36mFAISS.similarity_search_by_vector\u001b[0;34m(self, embedding, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_by_vector\u001b[39m(\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    448\u001b[0m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to embedding vector.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the embedding.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:314\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score_by_vector\u001b[0;34m(self, embedding, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# This happens when not enough docs are returned.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m _id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_to_docstore_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    315\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39msearch(_id)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, Document):\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# Retrieve lyrics using the query embedding\n",
    "\n",
    "# Example user query\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "def embed_user_query(user_input):\n",
    "    logger.info(\"Embedding user query using LangChain...\")\n",
    "    user_embedding = embeddings.embed_query(user_input)\n",
    "    logger.info(\"User query embedded.\")\n",
    "    user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "    print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "    return user_embedding\n",
    "\n",
    "\n",
    "user_query = \"summer happy vibes\"\n",
    "\n",
    "# Create an embedding for the user query\n",
    "query_embedding = embed_user_query(user_query)\n",
    "\n",
    "# Check if the embedding shape matches what FAISS expects (should be 2D, with one row per item)\n",
    "print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "\n",
    "def retrieve_songs(query):\n",
    "    # Preprocess the query to get embeddings\n",
    "    query_embedding = preprocess_query(query)\n",
    "    \n",
    "    # Search the FAISS indices\n",
    "    lyrics_distances, lyrics_indices = lyrics_index.search(query_embedding, k=5)\n",
    "    lyrics_results = [lyrics_data[idx] for idx in lyrics_indices[0]]\n",
    "    \n",
    "    audio_distances, audio_indices = audio_index.search(query_embedding, k=5)\n",
    "    audio_results = [tracks[idx] for idx in audio_indices[0]]\n",
    "    \n",
    "    # Combine and rank results\n",
    "    combined_results = merge_and_rank_results(lyrics_results, audio_results)\n",
    "    return combined_results\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_lyrics_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "    docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "lyrics_docs = retrieve_lyrics_with_langchain(query_embedding)\n",
    "\n",
    "# Check the results\n",
    "print(\"Lyrics retrieval results:\")\n",
    "for doc in lyrics_docs:\n",
    "    print(doc.metadata['title'], doc.metadata['artist'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up Spotify API...\n",
      "INFO:__main__:Setting up Genius API...\n",
      "INFO:__main__:Loading pre-trained transformer model...\n",
      "INFO:__main__:Fetching and processing data...\n",
      "INFO:__main__:Fetching top 5 tracks from Spotify...\n",
      "INFO:__main__:Fetched 5 tracks.\n",
      "INFO:__main__:Fetching audio features from Spotify...\n",
      "INFO:__main__:Fetched audio features for 5 tracks.\n",
      "INFO:__main__:Fetching lyrics for THE GREATEST by Billie Eilish from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"THE GREATEST\" by Billie Eilish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for THE GREATEST.\n",
      "INFO:__main__:Fetching lyrics for No Surprises by Radiohead from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"No Surprises\" by Radiohead...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for No Surprises.\n",
      "INFO:__main__:Fetching lyrics for Bunker by Balthazar from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"Bunker\" by Balthazar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Bunker.\n",
      "INFO:__main__:Fetching lyrics for Candy by Paolo Nutini from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"Candy\" by Paolo Nutini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Candy.\n",
      "INFO:__main__:Fetching lyrics for Fake Plastic Trees by Radiohead from Genius...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Searching for \"Fake Plastic Trees\" by Radiohead...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched lyrics for Fake Plastic Trees.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory usage: 1009.61 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: No Surprises, Artist: Radiohead\n",
      "Lyrics snippet: 145 ContributorsTranslationsDeutschEspaolFranaisNo Surprises Lyrics[Verse 1]\n",
      "A heart that's...\n",
      "\n",
      "Title: THE GREATEST, Artist: Billie Eilish\n",
      "Lyrics snippet: 70 ContributorsTranslationsHebrewPolskiDeutschPortugusEspaolItalianoTrkeFranais...\n",
      "\n",
      "Title: Fake Plastic Trees, Artist: Radiohead\n",
      "Lyrics snippet: 129 ContributorsTranslationsEspaolPortugusFranaisFake Plastic Trees Lyrics[Verse 1]\n",
      "A green plast...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# working version \n",
    "\n",
    "# Import essential libraries for the project\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import lyricsgenius\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import logging\n",
    "import psutil  # For monitoring system memory\n",
    "import gc  # For managing memory through garbage collection\n",
    "\n",
    "# Set up logging to monitor and log the flow of execution and potential issues\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "SPOTIFY_CLIENT_ID = '***REMOVED***'\n",
    "SPOTIFY_CLIENT_SECRET = '***REMOVED***'\n",
    "SPOTIFY_REDIRECT_URI = 'http://localhost:8888/callback'\n",
    "GENIUS_API_TOKEN = '***REMOVED***'\n",
    "\n",
    "\n",
    "# Initialize the Spotify API with user credentials for accessing music-related data\n",
    "logger.info(\"Setting up Spotify API...\")\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=SPOTIFY_CLIENT_ID,\n",
    "                                               client_secret=SPOTIFY_CLIENT_SECRET,\n",
    "                                               redirect_uri=SPOTIFY_REDIRECT_URI,\n",
    "                                               scope=\"user-top-read user-library-read playlist-read-private\"))\n",
    "\n",
    "# Initialize the Genius API with your credentials to fetch song lyrics\n",
    "logger.info(\"Setting up Genius API...\")\n",
    "genius = lyricsgenius.Genius(GENIUS_API_TOKEN)\n",
    "\n",
    "# Load a pre-trained transformer model and tokenizer for processing lyrics into embeddings\n",
    "logger.info(\"Loading pre-trained transformer model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Ensure the model operates on CPU to prevent GPU memory overflow issues\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define a function to embed textual data using the transformer model to get fixed-size numerical vectors\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "# Function to monitor and log the memory usage to manage resources efficiently\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    logger.info(f\"Memory usage: {mem_info.rss / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "# Retrieve and log the user's most listened tracks from Spotify\n",
    "def get_spotify_top_tracks(sp, limit=100, time_range='medium_term'):\n",
    "    logger.info(f\"Fetching top {limit} tracks from Spotify...\")\n",
    "    results = sp.current_user_top_tracks(limit=limit, time_range=time_range)\n",
    "    tracks = results['items']\n",
    "    logger.info(f\"Fetched {len(tracks)} tracks.\")\n",
    "    return tracks\n",
    "\n",
    "# Fetch and log playlists created by the user on Spotify\n",
    "def get_spotify_playlists(sp):\n",
    "    logger.info(\"Fetching user playlists from Spotify...\")\n",
    "    results = sp.current_user_playlists()\n",
    "    playlists = results['items']\n",
    "    logger.info(f\"Fetched {len(playlists)} playlists.\")\n",
    "    return playlists\n",
    "\n",
    "# Fetch and log the audio features of tracks from Spotify which includes metrics like tempo, energy, etc.\n",
    "def get_audio_features(sp, track_ids):\n",
    "    logger.info(\"Fetching audio features from Spotify...\")\n",
    "    audio_features = sp.audio_features(track_ids)\n",
    "    logger.info(f\"Fetched audio features for {len(audio_features)} tracks.\")\n",
    "    return audio_features\n",
    "\n",
    "# Retrieve and log lyrics for specified songs using the Genius API\n",
    "def get_lyrics(artist, title):\n",
    "    logger.info(f\"Fetching lyrics for {title} by {artist} from Genius...\")\n",
    "    song = genius.search_song(title, artist)\n",
    "    if song:\n",
    "        logger.info(f\"Fetched lyrics for {title}.\")\n",
    "        return song.lyrics\n",
    "    logger.warning(f\"Lyrics for {title} by {artist} not found.\")\n",
    "    return None\n",
    "\n",
    "# Convert audio features into a numerical vector for processing and comparison\n",
    "def audio_features_to_vector(audio_features):\n",
    "    vector = np.array([\n",
    "        audio_features['danceability'],\n",
    "        audio_features['energy'],\n",
    "        audio_features['speechiness'],\n",
    "        audio_features['acousticness'],\n",
    "        audio_features['instrumentalness'],\n",
    "        audio_features['liveness'],\n",
    "        audio_features['valence'],\n",
    "        audio_features['tempo']\n",
    "    ])\n",
    "    return vector\n",
    "\n",
    "# Batch processing to manage memory usage while fetching and processing data from Spotify\n",
    "def fetch_and_process_data(sp, limit=400, batch_size=20):\n",
    "    tracks = get_spotify_top_tracks(sp, limit=limit)\n",
    "    track_ids = [track['id'] for track in tracks]\n",
    "    audio_features = get_audio_features(sp, track_ids)\n",
    "    \n",
    "    lyrics_data = []\n",
    "    audio_vectors = []\n",
    "    metadata = []  # Store metadata for each track\n",
    "    \n",
    "    for i in range(0, len(tracks), batch_size):\n",
    "        batch_tracks = tracks[i:i+batch_size]\n",
    "        batch_audio_features = audio_features[i:i+batch_size]\n",
    "        \n",
    "        for track, audio_feature in zip(batch_tracks, batch_audio_features):\n",
    "            artist = track['artists'][0]['name']\n",
    "            title = track['name']\n",
    "            lyrics = get_lyrics(artist, title)\n",
    "            if lyrics:\n",
    "                lyrics_embedding = embed_text(lyrics)\n",
    "                audio_vector = audio_features_to_vector(audio_feature)\n",
    "                lyrics_data.append(lyrics_embedding)\n",
    "                audio_vectors.append(audio_vector)\n",
    "                metadata.append({'artist': artist, 'title': title, 'lyrics': lyrics})\n",
    "        \n",
    "        # Release memory after processing each batch\n",
    "        del batch_tracks, batch_audio_features\n",
    "        gc.collect()\n",
    "        log_memory_usage()\n",
    "    \n",
    "    lyrics_embeddings = np.vstack(lyrics_data)\n",
    "    audio_vectors = np.vstack(audio_vectors)\n",
    "    \n",
    "    return lyrics_embeddings, audio_vectors, metadata\n",
    "\n",
    "# Execute the data fetching and processing\n",
    "logger.info(\"Fetching and processing data...\")\n",
    "lyrics_embeddings, audio_vectors, metadata = fetch_and_process_data(sp, limit=5)\n",
    "\n",
    "# Create indices for the embeddings and vectors to facilitate efficient similarity searches\n",
    "lyrics_index = faiss.IndexFlatL2(lyrics_embeddings.shape[1])\n",
    "lyrics_index.add(lyrics_embeddings)\n",
    "\n",
    "audio_index = faiss.IndexFlatL2(audio_vectors.shape[1])\n",
    "audio_index.add(audio_vectors)\n",
    "\n",
    "# Function to retrieve similar lyrics using FAISS\n",
    "def retrieve_similar_lyrics(query_embedding, k=3):\n",
    "    _, indices = lyrics_index.search(query_embedding, k)\n",
    "    return [metadata[i] for i in indices[0]]\n",
    "\n",
    "# Example usage\n",
    "user_query = \"sad song about heartbreak\"\n",
    "query_embedding = embed_text(user_query)\n",
    "lyrics_results = retrieve_similar_lyrics(query_embedding)\n",
    "\n",
    "# Display results\n",
    "for result in lyrics_results:\n",
    "    print(f\"Title: {result['title']}, Artist: {result['artist']}\")\n",
    "    print(f\"Lyrics snippet: {result['lyrics'][:100]}...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
