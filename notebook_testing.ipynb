{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Project: Song Recommendation System Based on User Mood\n",
    "This project aims to create a system that suggests songs based on a user's mood. We will use Spotify and Genius APIs to fetch user data, process this data to create embeddings using a pre-trained transformer model, store these embeddings in a FAISS index, and use LangChain and MLflow to manage the retrieval and generation processes.\n",
    " Step-by-Step Guide\n",
    " \n",
    " 1. Setup Environment and Install Dependencies\n",
    "**Why:** To ensure all necessary packages and tools are available for the project.\n",
    "**Action:** Install the required libraries such as `lyricsgenius`, `spotipy`, `transformers`, `scikit-learn`, `faiss-cpu`, `tqdm`, and `mlflow`.\n",
    "**Commands:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lyricsgenius\n",
      "  Using cached lyricsgenius-3.0.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting beautifulsoup4>=4.6.0 (from lyricsgenius)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting requests>=2.20.0 (from lyricsgenius)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.6.0->lyricsgenius)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.20.0->lyricsgenius)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.20.0->lyricsgenius)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.20.0->lyricsgenius)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20.0->lyricsgenius)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached lyricsgenius-3.0.1-py3-none-any.whl (59 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, soupsieve, idna, charset-normalizer, certifi, requests, beautifulsoup4, lyricsgenius\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.7.4 charset-normalizer-3.3.2 idna-3.7 lyricsgenius-3.0.1 requests-2.32.3 soupsieve-2.6 urllib3-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spotipy\n",
      "  Using cached spotipy-2.24.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting redis>=3.5.3 (from spotipy)\n",
      "  Using cached redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: requests>=2.25.0 in ./.venv/lib/python3.10/site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.10/site-packages (from spotipy) (2.2.2)\n",
      "Collecting async-timeout>=4.0.3 (from redis>=3.5.3->spotipy)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (2024.7.4)\n",
      "Using cached spotipy-2.24.0-py3-none-any.whl (30 kB)\n",
      "Using cached redis-5.0.8-py3-none-any.whl (255 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: async-timeout, redis, spotipy\n",
      "Successfully installed async-timeout-4.0.3 redis-5.0.8 spotipy-2.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spotipy in ./.venv/lib/python3.10/site-packages (2.24.0)\n",
      "Requirement already satisfied: lyricsgenius in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (12 kB)\n",
      "Collecting gtts\n",
      "  Using cached gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: redis>=3.5.3 in ./.venv/lib/python3.10/site-packages (from spotipy) (5.0.8)\n",
      "Requirement already satisfied: requests>=2.25.0 in ./.venv/lib/python3.10/site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.10/site-packages (from spotipy) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in ./.venv/lib/python3.10/site-packages (from lyricsgenius) (4.12.3)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.0.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click<8.2,>=7.1 (from gtts)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.6)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in ./.venv/lib/python3.10/site-packages (from redis>=3.5.3->spotipy) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (2024.7.4)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa)\n",
      "  Using cached cffi-1.17.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "Downloading scikit_learn-1.5.1-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.0.8-cp310-cp310-macosx_11_0_arm64.whl (84 kB)\n",
      "Downloading numba-0.60.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.1-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading regex-2024.7.24-cp310-cp310-macosx_11_0_arm64.whl (278 kB)\n",
      "Using cached safetensors-0.4.4-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Using cached soxr-0.4.0-cp310-cp310-macosx_11_0_arm64.whl (387 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading cffi-1.17.0-cp310-cp310-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading llvmlite-0.43.0-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pydub, tqdm, threadpoolctl, safetensors, regex, pyyaml, pycparser, numpy, msgpack, llvmlite, lazy-loader, joblib, fsspec, filelock, click, audioread, soxr, scipy, pooch, numba, huggingface-hub, gtts, cffi, tokenizers, soundfile, scikit-learn, transformers, librosa\n",
      "Successfully installed audioread-3.0.1 cffi-1.17.0 click-8.1.7 filelock-3.15.4 fsspec-2024.6.1 gtts-2.5.3 huggingface-hub-0.24.5 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.0.8 numba-0.60.0 numpy-2.0.1 pooch-1.8.2 pycparser-2.22 pydub-0.25.1 pyyaml-6.0.2 regex-2024.7.24 safetensors-0.4.4 scikit-learn-1.5.1 scipy-1.14.0 soundfile-0.12.1 soxr-0.4.0 threadpoolctl-3.5.0 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
      "Collecting numpy<2.0,>=1.0 (from faiss-cpu)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
      "Using cached faiss_cpu-1.8.0.post1-cp310-cp310-macosx_11_0_arm64.whl (6.0 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Installing collected packages: numpy, faiss-cpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed faiss-cpu-1.8.0.post1 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.0-cp310-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 sympy-1.13.2 torch-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lyricsgenius in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: spotipy in ./.venv/lib/python3.10/site-packages (2.24.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.44.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: gtts in ./.venv/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: pydub in ./.venv/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: librosa in ./.venv/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.10/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (4.66.5)\n",
      "Collecting mlflow\n",
      "  Using cached mlflow-2.15.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in ./.venv/lib/python3.10/site-packages (from lyricsgenius) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in ./.venv/lib/python3.10/site-packages (from lyricsgenius) (2.32.3)\n",
      "Requirement already satisfied: redis>=3.5.3 in ./.venv/lib/python3.10/site-packages (from spotipy) (5.0.8)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.10/site-packages (from spotipy) (2.2.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.venv/lib/python3.10/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in ./.venv/lib/python3.10/site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.venv/lib/python3.10/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.venv/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.venv/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.10/site-packages (from librosa) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.venv/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.10/site-packages (from librosa) (1.0.8)\n",
      "Collecting mlflow-skinny==2.15.1 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.15.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting matplotlib<4 (from mlflow)\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Using cached pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pyarrow<16,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting querystring-parser<2 (from mlflow)\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Using cached SQLAlchemy-2.0.32-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in ./.venv/lib/python3.10/site-packages (from mlflow) (3.1.4)\n",
      "Collecting gunicorn<23 (from mlflow)\n",
      "  Using cached gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached databricks_sdk-0.30.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting entrypoints<1 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf<6,>=3.12.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached protobuf-5.27.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pytz<2025 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.6)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask<4->mlflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
      "  Using cached aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Using cached contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4->mlflow)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow)\n",
      "  Downloading fonttools-4.53.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib<4->mlflow)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4->mlflow)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.venv/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Collecting tzdata>=2022.7 (from pandas<3->mlflow)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.10/site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in ./.venv/lib/python3.10/site-packages (from redis>=3.5.3->spotipy) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.20.0->lyricsgenius) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.20.0->lyricsgenius) (2024.7.4)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached google_auth-2.33.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached zipp-3.20.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached mlflow-2.15.1-py3-none-any.whl (26.3 MB)\n",
      "Using cached mlflow_skinny-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "Using cached gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading matplotlib-3.9.2-cp310-cp310-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pyarrow-15.0.2-cp310-cp310-macosx_11_0_arm64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Using cached SQLAlchemy-2.0.32-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl (244 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached databricks_sdk-0.30.0-py3-none-any.whl (538 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading fonttools-4.53.1-cp310-cp310-macosx_11_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
      "Using cached opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-5.27.3-cp38-abi3-macosx_10_9_universal2.whl (412 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached sqlparse-0.5.1-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached zipp-3.20.0-py3-none-any.whl (9.4 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: pytz, aniso8601, zipp, wrapt, Werkzeug, tzdata, sqlparse, sqlalchemy, smmap, querystring-parser, pyparsing, pyasn1, pyarrow, protobuf, pillow, markdown, Mako, kiwisolver, itsdangerous, gunicorn, graphql-core, fonttools, entrypoints, cycler, contourpy, cloudpickle, cachetools, blinker, rsa, pyasn1-modules, pandas, matplotlib, importlib-metadata, graphql-relay, gitdb, Flask, docker, deprecated, alembic, opentelemetry-api, graphene, google-auth, gitpython, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.0.3 Mako-1.3.5 Werkzeug-3.0.3 alembic-1.13.2 aniso8601-9.0.1 blinker-1.8.2 cachetools-5.4.0 cloudpickle-3.0.0 contourpy-1.2.1 cycler-0.12.1 databricks-sdk-0.30.0 deprecated-1.2.14 docker-7.1.0 entrypoints-0.4 fonttools-4.53.1 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.33.0 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 importlib-metadata-7.2.1 itsdangerous-2.2.0 kiwisolver-1.4.5 markdown-3.7 matplotlib-3.9.2 mlflow-2.15.1 mlflow-skinny-2.15.1 opentelemetry-api-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 pandas-2.2.2 pillow-10.4.0 protobuf-5.27.3 pyarrow-15.0.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 pyparsing-3.1.2 pytz-2024.1 querystring-parser-1.2.4 rsa-4.9 smmap-5.0.1 sqlalchemy-2.0.32 sqlparse-0.5.1 tzdata-2024.1 wrapt-1.16.0 zipp-3.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.10/site-packages (from uvicorn) (8.1.7)\n",
      "Collecting h11>=0.8 (from uvicorn)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in ./.venv/lib/python3.10/site-packages (from uvicorn) (4.12.2)\n",
      "Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: h11, uvicorn\n",
      "Successfully installed h11-0.14.0 uvicorn-0.30.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.10/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pydantic>=1.9 (from chromadb)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.19.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.10/site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.66.5)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.65.5-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.6 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.12.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.7-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->chromadb)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Collecting sniffio (from httpx>=0.27.0->chromadb)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.33.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (5.27.3)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.2.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.2.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.9->chromadb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=1.9->chromadb)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.24.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.20.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.23.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.10/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Using cached chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "Using cached chroma_hnswlib-0.7.6-cp310-cp310-macosx_11_0_arm64.whl (183 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "Using cached grpcio-1.65.5-cp310-cp310-macosx_12_0_universal2.whl (10.4 MB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached mmh3-4.1.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached onnxruntime-1.19.0-cp310-cp310-macosx_11_0_universal2.whl (16.8 MB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached orjson-3.10.7-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Downloading pydantic_core-2.20.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached typer-0.12.4-py3-none-any.whl (47 kB)\n",
      "Downloading importlib_resources-6.4.2-py3-none-any.whl (34 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "Using cached httptools-0.6.1-cp310-cp310-macosx_10_9_universal2.whl (149 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached uvloop-0.20.0-cp310-cp310-macosx_10_9_universal2.whl (1.4 MB)\n",
      "Using cached watchfiles-0.23.0-cp310-cp310-macosx_11_0_arm64.whl (369 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-macosx_11_0_arm64.whl (121 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, websockets, websocket-client, uvloop, tomli, tenacity, sniffio, shellingham, python-dotenv, pyproject_hooks, pydantic-core, protobuf, overrides, orjson, opentelemetry-util-http, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, httpcore, grpcio, chroma-hnswlib, bcrypt, backoff, asgiref, annotated-types, requests-oauthlib, pydantic, posthog, opentelemetry-proto, markdown-it-py, googleapis-common-protos, coloredlogs, build, anyio, watchfiles, starlette, rich, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, httpx, typer, opentelemetry-instrumentation-asgi, fastapi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.27.3\n",
      "    Uninstalling protobuf-5.27.3:\n",
      "      Successfully uninstalled protobuf-5.27.3\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.4.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 fastapi-0.112.1 flatbuffers-24.3.25 googleapis-common-protos-1.63.2 grpcio-1.65.5 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-resources-6.4.2 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.19.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-util-http-0.47b0 orjson-3.10.7 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.4 pydantic-2.8.2 pydantic-core-2.20.1 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.7.1 shellingham-1.5.4 sniffio-1.3.1 starlette-0.38.2 tenacity-9.0.0 tomli-2.0.1 typer-0.12.4 uvloop-0.20.0 watchfiles-0.23.0 websocket-client-1.8.0 websockets-12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting FlagEmbedding\n",
      "  Using cached FlagEmbedding-1.2.11-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.6.0 in ./.venv/lib/python3.10/site-packages (from FlagEmbedding) (2.4.0)\n",
      "Requirement already satisfied: transformers>=4.33.0 in ./.venv/lib/python3.10/site-packages (from FlagEmbedding) (4.44.0)\n",
      "Collecting datasets (from FlagEmbedding)\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting accelerate>=0.20.1 (from FlagEmbedding)\n",
      "  Using cached accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentence-transformers (from FlagEmbedding)\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (24.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (0.4.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (2024.6.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers>=4.33.0->FlagEmbedding) (2024.7.24)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers>=4.33.0->FlagEmbedding) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers>=4.33.0->FlagEmbedding) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers>=4.33.0->FlagEmbedding) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.10/site-packages (from datasets->FlagEmbedding) (15.0.2)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->FlagEmbedding)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets->FlagEmbedding) (2.2.2)\n",
      "Collecting xxhash (from datasets->FlagEmbedding)\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->FlagEmbedding)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets->FlagEmbedding)\n",
      "  Using cached aiohttp-3.10.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers->FlagEmbedding) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from sentence-transformers->FlagEmbedding) (1.14.0)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from sentence-transformers->FlagEmbedding) (10.4.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Downloading aiohappyeyeballs-2.3.6-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->FlagEmbedding)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.33.0->FlagEmbedding) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.33.0->FlagEmbedding) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.33.0->FlagEmbedding) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.33.0->FlagEmbedding) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->FlagEmbedding) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->FlagEmbedding) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->FlagEmbedding) (1.16.0)\n",
      "Using cached accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.10.3-cp310-cp310-macosx_11_0_arm64.whl (388 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.3.6-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "Installing collected packages: xxhash, multidict, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, accelerate, sentence-transformers, datasets, FlagEmbedding\n",
      "Successfully installed FlagEmbedding-1.2.11 accelerate-0.33.0 aiohappyeyeballs-2.3.6 aiohttp-3.10.3 aiosignal-1.3.1 attrs-24.2.0 datasets-2.21.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 sentence-transformers-3.0.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.10/site-packages (from langchain) (3.10.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n",
      "  Using cached langchain_core-0.2.33-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.32->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "Using cached langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_core-0.2.33-py3-none-any.whl (391 kB)\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-community-0.2.12 langchain-core-0.2.33 langchain-text-splitters-0.2.2 langsmith-0.1.99 marshmallow-3.21.3 mypy-extensions-1.0.0 tenacity-8.5.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting peft\n",
      "  Using cached peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.10/site-packages (from peft) (2.4.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (from peft) (4.44.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./.venv/lib/python3.10/site-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.10/site-packages (from peft) (0.4.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./.venv/lib/python3.10/site-packages (from peft) (0.24.5)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lyricsgenius\n",
    "%pip install spotipy\n",
    "%pip install spotipy lyricsgenius transformers scikit-learn gtts pydub librosa\n",
    "%pip install faiss-cpu\n",
    "%pip install tqdm\n",
    "%pip install torch\n",
    "%pip install lyricsgenius spotipy transformers scikit-learn gtts pydub librosa faiss-cpu tqdm mlflow\n",
    "%pip install torch  --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install uvicorn\n",
    "%pip install nest_asyncio\n",
    "%pip install chromadb\n",
    "%pip install -U FlagEmbedding\n",
    "%pip install langchain langchain-community\n",
    "%pip install sentence-transformers\n",
    "%pip install peft\n",
    "%pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\vaish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\vaish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paniz/Documents/GitHub/spotify/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries for the project\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import lyricsgenius\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import logging\n",
    "import psutil  # For monitoring system memory\n",
    "import gc  # For managing memory through garbage collection\n",
    "import dotenv\n",
    "import tqdm as notebook_tqdm\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to monitor and log the flow of execution and potential issues\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import logging\n",
    "# from fastapi import FastAPI, HTTPException, Request, Query\n",
    "# from fastapi.responses import RedirectResponse, JSONResponse\n",
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyOAuth\n",
    "# from dotenv import load_dotenv\n",
    "# import lyricsgenius\n",
    "# from spotipy.exceptions import SpotifyException\n",
    "# import chromadb\n",
    "# from chromadb.errors import InvalidCollectionException\n",
    "# # Import BGEM3FlagModel from FlagEmbedding\n",
    "# from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "# # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Initialize FastAPI app\n",
    "# app = FastAPI()\n",
    "\n",
    "# # Spotify OAuth configuration\n",
    "# sp_oauth = SpotifyOAuth(\n",
    "#     client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "#     client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    "#     redirect_uri=\"http://localhost:8235/callback\",  # Ensure this matches your registered Spotify redirect URI\n",
    "#     scope=\"user-top-read user-library-read playlist-read-private\"\n",
    "# )\n",
    "\n",
    "# # Initialize Genius API\n",
    "# genius = lyricsgenius.Genius(os.getenv(\"GENIUS_API_TOKEN\"))\n",
    "\n",
    "# # Initialize ChromaDB client\n",
    "# client = chromadb.Client()\n",
    "\n",
    "\n",
    "# # Load the BGEM3FlagModel\n",
    "# model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# def get_spotify_client():\n",
    "#     token_info = sp_oauth.get_cached_token()\n",
    "\n",
    "#     if not token_info:\n",
    "#         # No valid token, redirect to Spotify authorization\n",
    "#         raise HTTPException(status_code=307, detail=\"Redirecting to Spotify authorization\", headers={\"Location\": \"/login\"})\n",
    "\n",
    "#     access_token = token_info['access_token']\n",
    "#     sp = spotipy.Spotify(auth=access_token)\n",
    "#     return sp\n",
    "\n",
    "# def get_audio_features_and_analysis(sp, track_id):\n",
    "#     audio_features = sp.audio_features([track_id])[0]  # Fetching audio features\n",
    "#     audio_analysis = sp.audio_analysis(track_id)       # Fetching audio analysis\n",
    "#     return {\n",
    "#         \"audio_features\": audio_features,\n",
    "#         \"audio_analysis\": audio_analysis\n",
    "#     }\n",
    "\n",
    "# def generate_embedding(text: str) -> list:\n",
    "#     # Use the BGEM3FlagModel to generate embeddings\n",
    "#     embedding = model.encode(text,return_colbert_vecs=True)  # Replace with the actual method for generating embeddings\n",
    "#     return embedding\n",
    "\n",
    "# def store_track_embedding(user_id: str, track_info: dict, embedding: list):\n",
    "    \n",
    "#     #check if the user has a collection and either create or get it\n",
    "#     collection_name = f\"{user_id}_liked_songs\"\n",
    "#     if collection_name not in client.list_collections():\n",
    "#         collection = client.create_collection(collection_name)\n",
    "\n",
    "#     else:\n",
    "#         collection = client.get_collection(collection_name)\n",
    "    \n",
    "\n",
    "#     # Store the track information and embedding in ChromaDB\n",
    "#     collection.upsert(\n",
    "#         ids=[track_info['id']],\n",
    "#         metadatas=[track_info],\n",
    "#         embeddings=[embedding]\n",
    "#     )\n",
    "\n",
    "# @app.get(\"/\")\n",
    "# async def read_root():\n",
    "#     return {\"message\": \"Welcome to the Spotify integration with FastAPI\"}\n",
    "\n",
    "# @app.get(\"/login\")\n",
    "# async def login():\n",
    "#     # Step 1: Redirect the user to Spotify's authorization page\n",
    "#     auth_url = sp_oauth.get_authorize_url()\n",
    "#     logger.info(f\"Redirecting to Spotify's authorization URL: {auth_url}\")\n",
    "#     return RedirectResponse(auth_url)\n",
    "\n",
    "# @app.get(\"/callback\")\n",
    "# async def callback(request: Request):\n",
    "#     # Step 2: Handle the redirect from Spotify and get the access token\n",
    "#     code = request.query_params.get('code')\n",
    "#     if not code:\n",
    "#         raise HTTPException(status_code=400, detail=\"Missing authorization code\")\n",
    "\n",
    "#     token_info = sp_oauth.get_access_token(code)\n",
    "\n",
    "#     if token_info:\n",
    "#         logger.info(\"Access token obtained successfully!\")\n",
    "#         # Redirect to a default page or the originally requested page\n",
    "#         return RedirectResponse(url=\"/\")\n",
    "#     else:\n",
    "#         raise HTTPException(status_code=401, detail=\"Could not authenticate with Spotify\")\n",
    "\n",
    "# @app.get(\"/liked_songs\")\n",
    "# async def liked_songs(limit: int = Query(default=100, description=\"Number of liked songs to fetch\")):\n",
    "#     try:\n",
    "#         sp = get_spotify_client()\n",
    "#         liked_songs = sp.current_user_saved_tracks(limit=limit)\n",
    "#         detailed_songs = []\n",
    "\n",
    "#         for item in liked_songs['items']:\n",
    "#             track = item['track']\n",
    "#             track_info = {\n",
    "#                 \"name\": track['name'],\n",
    "#                 \"album\": track['album']['name'],\n",
    "#                 \"artists\": [artist['name'] for artist in track['artists']],\n",
    "#                 \"url\": track['external_urls']['spotify']\n",
    "#             }\n",
    "#             track_details = get_audio_features_and_analysis(sp, track['id'])\n",
    "#             track_info.update(track_details)\n",
    "#             detailed_songs.append(track_info)\n",
    "        \n",
    "#         logger.info(f\"Number of liked songs retrieved: {len(liked_songs['items'])}\")\n",
    "#         logger.info(f\"Fetching liked songs up to limit: {min(limit, len(liked_songs['items']))}\")\n",
    "        \n",
    "#         return {\"liked_songs\": detailed_songs}\n",
    "#     except HTTPException as e:\n",
    "#         if e.status_code == 307:\n",
    "#             return RedirectResponse(url=\"/login\")\n",
    "#         raise e\n",
    "#     except SpotifyException as e:\n",
    "#         if e.http_status == 429:\n",
    "#             return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "#         else:\n",
    "#             return JSONResponse(status_code=500, content={\"message\": \"An error occurred while fetching liked songs.\"})\n",
    "\n",
    "# # @app.get(\"/lyrics\")\n",
    "# # async def lyrics(artist: str, title: str):\n",
    "# #     try:\n",
    "# #         song = genius.search_song(title, artist)\n",
    "# #         if song:\n",
    "# #             return {\"lyrics\": song.lyrics}\n",
    "# #         else:\n",
    "# #             raise HTTPException(status_code=404, detail=\"Lyrics not found\")\n",
    "# #     except HTTPException as e:\n",
    "# #         raise e\n",
    "\n",
    "# # @app.get(\"/singleplaylist\")\n",
    "# # async def singleplaylist(playlist_id: str):\n",
    "# #     try:\n",
    "# #         sp = get_spotify_client()\n",
    "# #         playlist = sp.playlist(playlist_id)\n",
    "# #         detailed_playlist = {\n",
    "# #             \"name\": playlist['name'],\n",
    "# #             \"tracks\": []\n",
    "# #         }\n",
    "\n",
    "# #         for track in playlist['tracks']['items']:\n",
    "# #             track_info = {\n",
    "# #                 \"name\": track['track']['name'],\n",
    "# #                 \"album\": track['track']['album']['name'],\n",
    "# #                 \"artists\": [artist['name'] for artist in track['track']['artists']],\n",
    "# #                 \"url\": track['track']['external_urls']['spotify']\n",
    "# #             }\n",
    "# #             track_details = get_audio_features_and_analysis(sp, track['track']['id'])\n",
    "# #             track_info.update(track_details)\n",
    "# #             detailed_playlist['tracks'].append(track_info)\n",
    "        \n",
    "# #         return {\"playlist\": detailed_playlist}\n",
    "# #     except HTTPException as e:\n",
    "# #         if e.status_code == 307:\n",
    "# #             return RedirectResponse(url=\"/login\")\n",
    "# #         raise e\n",
    "\n",
    "# @app.get(\"/store_embeddings\")\n",
    "# async def store_embeddings(limit: int = Query(default=50, description=\"Number of liked songs to fetch\")):\n",
    "#     try:\n",
    "#         sp = get_spotify_client()\n",
    "#         liked_songs = sp.current_user_saved_tracks(limit=limit)\n",
    "#         embedded_count = 0\n",
    "#         user_id = sp.current_user()['id']\n",
    "\n",
    "#         for item in liked_songs['items']:\n",
    "#             if embedded_count >= limit:\n",
    "#                 break\n",
    "\n",
    "#             track = item['track']\n",
    "#             track_info = {\n",
    "#                 \"id\": track['id'],\n",
    "#                 \"name\": track['name'],\n",
    "#                 \"album\": track['album']['name'],\n",
    "#                 \"artists\": [artist['name'] for artist in track['artists']],\n",
    "#                 \"url\": track['external_urls']['spotify']\n",
    "#             }\n",
    "#             track_details = get_audio_features_and_analysis(sp, track['id'])\n",
    "#             track_info.update(track_details)\n",
    "\n",
    "#             # Generate embedding\n",
    "#             track_text = f\"{track_info['name']} by {track_info['artists'][0]} from {track_info['album']}\"\n",
    "#             embedding = generate_embedding(track_text)\n",
    "\n",
    "#             # Store data in ChromaDB\n",
    "#             store_track_embedding(user_id, track_info, embedding)\n",
    "#             embedded_count += 1\n",
    "\n",
    "#         logger.info(f\"Number of songs embedded: {embedded_count}\")\n",
    "\n",
    "#         return {\"message\": f\"Successfully embedded {embedded_count} songs\"}\n",
    "#     except HTTPException as e:\n",
    "#         if e.status_code == 307:\n",
    "#             return RedirectResponse(url=\"/login\")\n",
    "#         raise e\n",
    "#     except SpotifyException as e:\n",
    "#         if e.http_status == 429:\n",
    "#             return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "#         else:\n",
    "#             return JSONResponse(status_code=500, content={\"message\": \"An error occurred while embedding songs.\"})\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import uvicorn\n",
    "#     import nest_asyncio\n",
    "#     import asyncio\n",
    "    \n",
    "#     nest_asyncio.apply()\n",
    "\n",
    "#     async def start_server():\n",
    "#         config = uvicorn.Config(app, host=\"127.0.0.1\", port=8235)\n",
    "#         server = uvicorn.Server(config)\n",
    "#         await server.serve()\n",
    "\n",
    "#     # Await the start_server function directly\n",
    "#     await start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. **Initialize ChromaDB Client**:\n",
    "#    - Create a ChromaDB client instance.\n",
    "   \n",
    "# 2. **Initialize Embedding Model**:\n",
    "#    - Load the BGEM3FlagModel for generating embeddings.\n",
    "\n",
    "# 3. **Define Function to Store User Data in ChromaDB**:\n",
    "#    - Check if the ChromaDB collection (e.g., \"spotify_embeddings\") exists.\n",
    "#      - If it doesn't exist, create the collection.\n",
    "#      - Otherwise, retrieve the existing collection.\n",
    "#    - Add the user's data (track info and embedding) to the collection using a unique ID.\n",
    "\n",
    "# 4. **Define `/store_embeddings` Endpoint**:\n",
    "#    - Get the Spotify client.\n",
    "#    - Fetch the user's liked songs, limiting the number of songs retrieved to 50.\n",
    "#    - Initialize a counter (`embedded_count`) to track the number of songs processed.\n",
    "   \n",
    "#    - **For each song in the liked songs list**:\n",
    "#      - If the counter reaches 50, break the loop.\n",
    "#      - Retrieve track information (e.g., name, album, artists, URL).\n",
    "#      - Fetch additional track details (audio features and analysis).\n",
    "#      - Update the track information with these details.\n",
    "     \n",
    "#      - **Generate Embedding**:\n",
    "#        - Create a text representation of the track (e.g., \"Track name by Artist from Album\").\n",
    "#        - Generate the embedding using the model.\n",
    "     \n",
    "#      - **Store Data in ChromaDB**:\n",
    "#        - Store the user ID, track information, and embedding in ChromaDB.\n",
    "     \n",
    "#      - Increment the counter.\n",
    "\n",
    "#    - Return a success message with the number of songs embedded.\n",
    "\n",
    "# 5. **Handle Exceptions**:\n",
    "#    - If the Spotify token is invalid, redirect to the login page.\n",
    "#    - If other exceptions occur, raise the appropriate HTTP exception.\n",
    "\n",
    "# ### Example Flow:\n",
    "\n",
    "# - User requests to store embeddings via the `/store_embeddings` endpoint.\n",
    "# - The system retrieves up to 50 liked songs.\n",
    "# - For each song, it generates an embedding and stores it in ChromaDB, ensuring the limit of 50 songs is not exceeded.\n",
    "# - The endpoint responds with a success message indicating how many songs were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "# # we need to save the data first and then convert it to chroma format \n",
    "# # might want to do as key being user then value being the stats of the data \n",
    "# chroma_client = chromadb.Client()\n",
    "\n",
    "\n",
    "# # TODO : add the user to the database\n",
    "# # TODO : add the song embeddings to the database using the prev cell \n",
    "\n",
    "# # sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "# # sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "# #                \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "# # output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "# # output_2 = model.encode(sentences_2, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "\n",
    "# # print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][0]))\n",
    "# # print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][1]))\n",
    "# # # 0.7797\n",
    "# # # 0.4620\n",
    "\n",
    "\n",
    "# from FlagEmbedding import BGEM3FlagModel\n",
    "# # model we are using for mebedding as colbert vector \n",
    "\n",
    "# #indexing model\n",
    "# model = BGEM3FlagModel('BAAI/bge-m3',  use_fp16=True) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO UPDATE THE USER QUERY SAME AS THE WAY WE STORE IT \n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "# def embed_user_query(user_input):\n",
    "#     logger.info(\"Embedding user query using LangChain...\")\n",
    "#     user_embedding = embeddings.embed_query(user_input)\n",
    "#     logger.info(\"User query embedded.\")\n",
    "#     user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "#     print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "#     return user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR ME FROM HERE ONWARD \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # steps 5\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "\n",
    "# def retrieve_lyrics_with_langchain(query_embedding):\n",
    "#     logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "#     retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "#     docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "#     logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "#     return docs\n",
    "\n",
    "# def retrieve_audio_features_with_langchain(query_embedding):\n",
    "#     logger.info(\"Performing audio feature retrieval using LangChain...\")\n",
    "#     retriever = FAISS(embedding_function=embeddings.embed_query, index=audio_index)\n",
    "#     docs = retriever.similarity_search(query_embedding, k=5)\n",
    "#     logger.info(f\"Retrieved top 5 audio features using LangChain.\")\n",
    "#     return docs\n",
    "    \n",
    "# def combine_retrieval_results(lyrics_docs, audio_docs):\n",
    "#     logger.info(\"Combining retrieval results...\")\n",
    "#     combined_results = lyrics_docs + audio_docs  # This could be a simple concatenation or more sophisticated merging\n",
    "#     logger.info(f\"Combined {len(combined_results)} results.\")\n",
    "#     return combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use the above in the cell w retrieve lyrics w langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step 6\n",
    "# def format_recommendations(retrieved_docs):\n",
    "#     logger.info(\"Formatting recommendations...\")\n",
    "#     formatted_response = \"\\n\".join([f\"Song: {doc.metadata['title']} by {doc.metadata['artist']}\\n{doc.page_content[:100]}...\" for doc in retrieved_docs])\n",
    "#     logger.info(\"Recommendations formatted.\")\n",
    "#     return formatted_response\n",
    "\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Initialize the generation pipeline using an open-source model\n",
    "# generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# def generate_personalized_response(formatted_recommendations, user_query):\n",
    "#     logger.info(\"Generating personalized response using LangChain...\")\n",
    "#     response = generator(f\"Context: {formatted_recommendations}\\n\\nQuestion: {user_query}\\nAnswer:\", max_length=200, num_return_sequences=1)\n",
    "#     return response[0]['generated_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve lyrics using the query embedding\n",
    "\n",
    "# # Example user query\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "# def embed_user_query(user_input):\n",
    "#     logger.info(\"Embedding user query using LangChain...\")\n",
    "#     user_embedding = embeddings.embed_query(user_input)\n",
    "#     logger.info(\"User query embedded.\")\n",
    "#     user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "#     print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "#     return user_embedding\n",
    "\n",
    "\n",
    "# user_query = \"summer happy vibes\"\n",
    "\n",
    "# # Create an embedding for the user query\n",
    "# query_embedding = embed_user_query(user_query)\n",
    "\n",
    "# # Check if the embedding shape matches what FAISS expects (should be 2D, with one row per item)\n",
    "# print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "\n",
    "# def retrieve_songs(query):\n",
    "#     # Preprocess the query to get embeddings\n",
    "#     query_embedding = preprocess_query(query)\n",
    "    \n",
    "#     # Search the FAISS indices\n",
    "#     lyrics_distances, lyrics_indices = lyrics_index.search(query_embedding, k=5)\n",
    "#     lyrics_results = [lyrics_data[idx] for idx in lyrics_indices[0]]\n",
    "    \n",
    "#     audio_distances, audio_indices = audio_index.search(query_embedding, k=5)\n",
    "#     audio_results = [tracks[idx] for idx in audio_indices[0]]\n",
    "    \n",
    "#     # Combine and rank results\n",
    "#     combined_results = merge_and_rank_results(lyrics_results, audio_results)\n",
    "#     return combined_results\n",
    "\n",
    "\n",
    "\n",
    "# def retrieve_lyrics_with_langchain(query_embedding):\n",
    "#     logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "#     retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "#     docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "#     logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "#     return docs\n",
    "\n",
    "\n",
    "# lyrics_docs = retrieve_lyrics_with_langchain(query_embedding)\n",
    "\n",
    "# # Check the results\n",
    "# print(\"Lyrics retrieval results:\")\n",
    "# for doc in lyrics_docs:\n",
    "#     print(doc.metadata['title'], doc.metadata['artist'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 8664.72it/s]\n",
      "INFO:FlagEmbedding.BGE_M3.modeling:loading existing colbert_linear and sparse_linear---------\n",
      "/Users/paniz/Documents/GitHub/spotify/.venv/lib/python3.10/site-packages/FlagEmbedding/BGE_M3/modeling.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  colbert_state_dict = torch.load(os.path.join(model_dir, 'colbert_linear.pt'), map_location='cpu')\n",
      "/Users/paniz/Documents/GitHub/spotify/.venv/lib/python3.10/site-packages/FlagEmbedding/BGE_M3/modeling.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sparse_state_dict = torch.load(os.path.join(model_dir, 'sparse_linear.pt'), map_location='cpu')\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "INFO:     Started server process [31067]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8235 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59738 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59738 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59738 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Redirecting to Spotify's authorization URL: https://accounts.spotify.com/authorize?client_id=10cc8ee290404da9ab9d7b061d526193&response_type=code&redirect_uri=http%3A%2F%2Flocalhost%3A8235%2Fcallback&scope=user-top-read+user-library-read+playlist-read-private+playlist-modify-public+playlist-modify-private\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59738 - \"GET /login HTTP/1.1\" 307 Temporary Redirect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Redirecting to Spotify's authorization URL: https://accounts.spotify.com/authorize?client_id=10cc8ee290404da9ab9d7b061d526193&response_type=code&redirect_uri=http%3A%2F%2Flocalhost%3A8235%2Fcallback&scope=user-top-read+user-library-read+playlist-read-private+playlist-modify-public+playlist-modify-private\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59738 - \"GET /login HTTP/1.1\" 307 Temporary Redirect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tq/51lzs6fs387bwv1r_7v0yn9w0000gn/T/ipykernel_31067/878371736.py:132: DeprecationWarning: You're using 'as_dict = True'.get_access_token will return the token string directly in future versions. Please adjust your code accordingly, or use get_cached_token instead.\n",
      "  token_info = sp_oauth.get_access_token(code)\n",
      "INFO:__main__:Access token obtained successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59738 - \"GET /callback?code=AQDZuD0TCJXbULt7ci9hfF2ZHYgzkvTySt54-G70E0ciPSux3IFkdgYdXIkXPSF7bIqMW79tw-BsitRtOFOYfJSNHbJMnM-H4NzYKL6-Z1U82_cNBrVK_13jhGViGIwXhSob2vHyFXQ3HBQtJDDSK8dNx3--LeFQ4xmgRF6tNYz14YS62_GHQoIlJnFxRxYF1LhrQtJTw7_dq3TbeJwty1nztLswTRVdvwtCriw625aBP251ZTnXRs2hMJyioHLXrKi6RxwsV3qo6g5ftlUPDqtjjM7A6hXcwPg8qRBLEjFiogvKndYNJJ2yCD0 HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:59738 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59738 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59738 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "Searching for \"Sabr 2\" by Shayea...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Number of songs embedded for user eqanbww3jh63cgf4ot5zyyr5d: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59740 - \"GET /store_embeddings?limit=1 HTTP/1.1\" 200 OK\n",
      "Searching for \"Summer Wine\" by Nancy Sinatra...\n",
      "Done.\n",
      "Searching for \"Ta Yeja\" by Shayea...\n",
      "Done.\n",
      "Searching for \"Sabr 2\" by Shayea...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Number of songs embedded for user eqanbww3jh63cgf4ot5zyyr5d: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59762 - \"GET /store_embeddings?limit=3 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [31067]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from fastapi import FastAPI, HTTPException, Request, Query\n",
    "from fastapi.responses import RedirectResponse, JSONResponse\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "from spotipy.exceptions import SpotifyException\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from uuid import uuid4\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Spotify OAuth configuration\n",
    "sp_oauth = SpotifyOAuth(\n",
    "    client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    "    redirect_uri=\"http://localhost:8235/callback\",\n",
    "    scope=\"user-top-read user-library-read playlist-read-private playlist-modify-public playlist-modify-private\"\n",
    ")\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius(os.getenv(\"GENIUS_API_TOKEN\"))\n",
    "\n",
    "# Initialize the BGEM3FlagModel for generating real embeddings\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "def get_spotify_client():\n",
    "    token_info = sp_oauth.get_cached_token()\n",
    "\n",
    "    if not token_info:\n",
    "        raise HTTPException(status_code=307, detail=\"Redirecting to Spotify authorization\", headers={\"Location\": \"/login\"})\n",
    "\n",
    "    access_token = token_info['access_token']\n",
    "    sp = spotipy.Spotify(auth=access_token)\n",
    "    return sp\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings \n",
    "\n",
    "# Initialize the BGEM3FlagModel for generating real embeddings\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "\n",
    "embedding_function = HuggingFaceBgeEmbeddings(model_name=model_name)\n",
    "\n",
    "def get_text_collection(user_id: str):\n",
    "    # Create a unique collection name for textual data based on user ID\n",
    "    collection_name = f\"{user_id}_text_collection\"\n",
    "    \n",
    "    # Initialize Chroma vector store for text data with the embedding function\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_function,\n",
    "        persist_directory=\"./chroma_langchain_db\"\n",
    "    )\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "def get_audio_collection(user_id: str):\n",
    "    # Create a unique collection name for audio data based on user ID\n",
    "    collection_name = f\"{user_id}_audio_collection\"\n",
    "    \n",
    "    # Initialize Chroma vector store for audio data (no embeddings needed)\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "         embedding_function=embedding_function,\n",
    "        persist_directory=\"./chroma_langchain_db\"\n",
    "    )\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "def get_audio_features_and_analysis(sp, track_id):\n",
    "    audio_features = sp.audio_features([track_id])[0]  # Fetching audio features\n",
    "    audio_analysis = sp.audio_analysis(track_id)       # Fetching audio analysis\n",
    "    return {\n",
    "        \"audio_features\": audio_features,\n",
    "        \"audio_analysis\": audio_analysis\n",
    "    }\n",
    "\n",
    "\n",
    "def filter_none_metadata(metadata):\n",
    "    \"\"\"\n",
    "    Recursively filters out None values from the metadata dictionary.\n",
    "    \"\"\"\n",
    "    if isinstance(metadata, dict):\n",
    "        return {k: filter_none_metadata(v) for k, v in metadata.items() if v is not None}\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# @app.get(\"/lyrics\")\n",
    "# async def lyrics(artist: str, title: str):\n",
    "#     try:\n",
    "#         song = genius.search_song(title, artist)\n",
    "#         if song:\n",
    "#             return {\"lyrics\": song.lyrics}\n",
    "#         else:\n",
    "#             raise HTTPException(status_code=404, detail=\"Lyrics not found\")\n",
    "#     except HTTPException as e:\n",
    "#         raise e\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "    return {\"message\": \"Welcome to the Spotify integration with FastAPI\"}\n",
    "\n",
    "@app.get(\"/login\")\n",
    "async def login():\n",
    "    auth_url = sp_oauth.get_authorize_url()\n",
    "    logger.info(f\"Redirecting to Spotify's authorization URL: {auth_url}\")\n",
    "    return RedirectResponse(auth_url)\n",
    "\n",
    "@app.get(\"/callback\")\n",
    "async def callback(request: Request):\n",
    "    code = request.query_params.get('code')\n",
    "    if not code:\n",
    "        raise HTTPException(status_code=400, detail=\"Missing authorization code\")\n",
    "\n",
    "    token_info = sp_oauth.get_access_token(code)\n",
    "\n",
    "    if token_info:\n",
    "        logger.info(\"Access token obtained successfully!\")\n",
    "        return RedirectResponse(url=\"/\")\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Could not authenticate with Spotify\")\n",
    "\n",
    "import json\n",
    "\n",
    "def convert_lists_to_strings(metadata):\n",
    "    \"\"\"\n",
    "    Convert lists in the metadata to JSON strings before storing them in ChromaDB.\n",
    "    Convert None values to empty strings.\n",
    "    \"\"\"\n",
    "    new_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        if value is None:\n",
    "            new_metadata[key] = \"\"  # Convert None to empty string\n",
    "        elif isinstance(value, list):\n",
    "            new_metadata[key] = json.dumps(value)\n",
    "        elif isinstance(value, dict):\n",
    "            new_metadata[key] = convert_lists_to_strings(value)  # Recursively handle nested dictionaries\n",
    "        else:\n",
    "            new_metadata[key] = value\n",
    "    return new_metadata\n",
    "\n",
    "\n",
    "def convert_strings_to_lists(metadata):\n",
    "    \"\"\"\n",
    "    Convert JSON strings in the metadata back to lists after retrieving them from ChromaDB.\n",
    "    \"\"\"\n",
    "    new_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        try:\n",
    "            # Try to convert the string back to a list\n",
    "            new_metadata[key] = json.loads(value) if isinstance(value, str) else value\n",
    "        except json.JSONDecodeError:\n",
    "            # If it's not a valid JSON string, keep the value as is\n",
    "            new_metadata[key] = value\n",
    "    return new_metadata\n",
    "\n",
    "@app.get(\"/store_embeddings\")\n",
    "async def store_embeddings(limit: int = Query(default=50, description=\"Number of liked songs to fetch\")):\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "                \n",
    "                # Get the current user's ID as early as possible\n",
    "        user_id = sp.current_user()['id']  # Get the current user's ID\n",
    "\n",
    "                # Get the text collection\n",
    "        text_store = get_text_collection(user_id)\n",
    "                        \n",
    "                # Get the current number of songs in the collection\n",
    "        curr_number_of_songs = text_store._collection.count()\n",
    "        \n",
    "        # Determine the offset for the Spotify API request\n",
    "        if curr_number_of_songs >= limit:\n",
    "            offset = curr_number_of_songs - limit\n",
    "        else:\n",
    "            offset = 0\n",
    "\n",
    "        liked_songs = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "        user_id = sp.current_user()['id']  # Get the current user's ID\n",
    "\n",
    "        # Get or create vector stores for text and audio data\n",
    "        text_store = get_text_collection(user_id)\n",
    "        audio_store = get_audio_collection(user_id)\n",
    "\n",
    "        text_documents = []\n",
    "        audio_documents = []\n",
    "        ids = []\n",
    "\n",
    "        for item in liked_songs['items']:\n",
    "            track = item['track']\n",
    "            track_id = track['id']\n",
    "            track_info = {\n",
    "                \"id\": track_id,\n",
    "                \"name\": track['name'],\n",
    "                \"album\": track['album']['name'],\n",
    "                \"artists\": [artist['name'] for artist in track['artists']],\n",
    "                \"url\": track['external_urls']['spotify']\n",
    "            }\n",
    "\n",
    "            # Convert lists to JSON strings in track_info\n",
    "            track_info = convert_lists_to_strings(track_info)\n",
    "\n",
    "            # Handle potential None values in track_info\n",
    "            track_info = filter_none_metadata(track_info)\n",
    "\n",
    "            song_lyrics = None\n",
    "            artist_name = json.loads(track_info[\"artists\"])[0]  # Get the first artist's name\n",
    "            song = genius.search_song(track_info[\"name\"], artist_name)\n",
    "            if song:\n",
    "                song_lyrics = song.lyrics or \"\"\n",
    "\n",
    "            # Create the document for the text collection\n",
    "            text_doc = Document(\n",
    "                page_content=f\"{track_info['name']} by {json.loads(track_info['artists'])} from {track_info['album']}\\nLyrics: {song_lyrics}\",\n",
    "                metadata={\"url\": track_info[\"url\"], \"track_id\": track_id},\n",
    "            )\n",
    "            text_documents.append(text_doc)\n",
    "            ids.append(track_id)  # Use track ID as the document ID for both collections\n",
    "\n",
    "            # Get audio features and analysis\n",
    "            audio_data = sp.audio_features([track_id])[0]  # Fetching audio features for the track\n",
    "            \n",
    "            # Convert lists to JSON strings in audio_data\n",
    "            audio_data = convert_lists_to_strings(audio_data)\n",
    "\n",
    "            # Handle potential None values in audio_data\n",
    "            audio_data = filter_none_metadata(audio_data)\n",
    "\n",
    "            # Combine the track_info and audio features into a single metadata dictionary\n",
    "            combined_metadata = {**track_info, **audio_data, \"lyrics\": song_lyrics}\n",
    "\n",
    "            # Handle potential None values in combined_metadata\n",
    "            combined_metadata = filter_none_metadata(combined_metadata)\n",
    "\n",
    "            # Create the document for the audio collection\n",
    "            audio_doc = Document(\n",
    "                page_content=\"Audio features and analysis data\",\n",
    "                metadata=combined_metadata,\n",
    "            )\n",
    "            audio_documents.append(audio_doc)\n",
    "\n",
    "        # Store the documents in the respective vector stores\n",
    "        text_store.add_documents(documents=text_documents, ids=ids)\n",
    "        audio_store.add_documents(documents=audio_documents, ids=ids)\n",
    "        \n",
    "        logger.info(f\"Number of songs embedded for user {user_id}: {len(text_documents)}\")\n",
    "\n",
    "        return {\"message\": f\"Successfully embedded {len(text_documents)} songs for user {user_id}\"}\n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "    except SpotifyException as e:\n",
    "        if e.http_status == 429:\n",
    "            return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "        else:\n",
    "            return JSONResponse(status_code=500, content={\"message\": \"An error occurred while embedding songs.\"})\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@app.get(\"/search\")\n",
    "async def search(query: str, k: int = Query(default=5, description=\"Number of results to fetch\")):\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "        user_id = sp.current_user()['id']  # Get the current user's ID\n",
    "\n",
    "        # Get text collection for this user\n",
    "        text_store = get_text_collection(user_id)\n",
    "        audio_store = get_audio_collection(user_id)\n",
    "\n",
    "        # Perform similarity search in text collection\n",
    "        text_results = text_store.similarity_search(query, k=k)\n",
    "\n",
    "        # Retrieve corresponding audio features and analysis based on track IDs\n",
    "        audio_results = []\n",
    "        for text_result in text_results:\n",
    "            track_id = text_result.metadata['track_id']\n",
    "            audio_result = audio_store.get([track_id])  # Retrieve audio data by track ID\n",
    "\n",
    "            # Log the audio_result for debugging purposes\n",
    "            logger.info(f\"Audio result for track_id {track_id}: {audio_result}\")\n",
    "\n",
    "            # Check if audio_result exists and is a non-empty list\n",
    "            if audio_result and isinstance(audio_result, list) and len(audio_result) > 0:\n",
    "                audio_metadata = audio_result[0].metadata\n",
    "                if audio_metadata:\n",
    "                    # Convert JSON strings back to lists in audio metadata\n",
    "                    audio_metadata = convert_strings_to_lists(audio_metadata)\n",
    "                audio_results.append(audio_metadata)\n",
    "            else:\n",
    "                logger.warning(f\"No valid audio data found for track_id {track_id}.\")\n",
    "                audio_results.append(None)\n",
    "\n",
    "        # Combine text and audio data for final output\n",
    "        combined_results = []\n",
    "        for text_result, audio_result in zip(text_results, audio_results):\n",
    "            combined_results.append({\n",
    "                \"text\": text_result.page_content,\n",
    "                \"metadata\": text_result.metadata,\n",
    "                \"audio\": audio_result\n",
    "            })\n",
    "            # print(f\"---------------------------Combined Result: {combined_results}\")\n",
    "        \n",
    "        # response_text = format_response(combined_results)\n",
    "        # return {\"results\": response_text}\n",
    "        return {\"results\": combined_results}\n",
    "    \n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "    except SpotifyException as e:\n",
    "        if e.http_status == 429:\n",
    "            return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "        else:\n",
    "            return JSONResponse(status_code=500, content={\"message\": \"An error occurred during the search process.\"})\n",
    "\n",
    "@app.post(\"/create_playlist\")\n",
    "async def create_playlist(query: str, k: int = Query(default=5, description=\"Number of results to fetch\")):\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "        user_id = sp.current_user()['id']  # Get the current user's ID\n",
    "\n",
    "        # Create a new playlist with the query as the name\n",
    "        playlist_name = query\n",
    "        playlist_description = f\"Playlist created based on the search query: {query}\"\n",
    "        new_playlist = sp.user_playlist_create(user_id, name=playlist_name, public=False, description=playlist_description)\n",
    "        playlist_id = new_playlist['id']\n",
    "        \n",
    "        logger.info(f\"Created new playlist: {playlist_name} with ID: {playlist_id}\")\n",
    "\n",
    "        # Search for songs and retrieve the results\n",
    "        combined_results = await search(query, k)\n",
    "        song_uris = []\n",
    "\n",
    "        # Extract URIs of tracks from the combined results\n",
    "        for result in combined_results['results']:\n",
    "            metadata = result['metadata']\n",
    "            if metadata and 'track_id' in metadata:\n",
    "                track_uri = f\"spotify:track:{metadata['track_id']}\"\n",
    "                song_uris.append(track_uri)\n",
    "\n",
    "        # Add songs to the playlist\n",
    "        if song_uris:\n",
    "            sp.playlist_add_items(playlist_id, song_uris)\n",
    "            logger.info(f\"Added {len(song_uris)} songs to the playlist: {playlist_name}\")\n",
    "        logger.info(f\"Created new playlist: {playlist_name} with ID: {playlist_id}\")\n",
    "        return {\"message\": f\"Playlist '{playlist_name}' created and {len(song_uris)} songs added.\"}\n",
    "    \n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "    except SpotifyException as e:\n",
    "        if e.http_status == 429:\n",
    "            return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "        else:\n",
    "            return JSONResponse(status_code=500, content={\"message\": \"An error occurred while creating the playlist.\"})\n",
    "\n",
    "@app.get(\"/get_recommendations\")\n",
    "async def get_recommendations(query: str, k: int = Query(default=5, description=\"Number of search results to fetch\")):\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "        user_id = sp.current_user()['id']  # Get the current user's ID\n",
    " \n",
    "        # Step 1: Perform the search and retrieve results\n",
    "        search_results = await search(query, k)\n",
    "        seed_tracks = []\n",
    "        seed_artists = []\n",
    "        seed_genres = []\n",
    " \n",
    "        for result in search_results['results']:\n",
    "            metadata = result['metadata']\n",
    "            if metadata and 'track_id' in metadata:\n",
    "                seed_tracks.append(metadata['track_id'])\n",
    "            if metadata and 'artists' in metadata:\n",
    "                seed_artists.extend(metadata['artists'])  # Assuming artists' IDs are stored in metadata\n",
    " \n",
    "        # Use only up to 5 seeds as required by Spotify API\n",
    "        seed_tracks = seed_tracks[:5]\n",
    "        seed_artists = seed_artists[:5]\n",
    " \n",
    "        # Step 2: Get recommendations based on seeds\n",
    "        recommendations = sp.recommendations(\n",
    "            seed_tracks=seed_tracks,\n",
    "            seed_artists=seed_artists,\n",
    "            seed_genres=seed_genres,\n",
    "            limit=10,  # Adjust the limit as needed\n",
    "            market=\"US\"  # Adjust the market as needed\n",
    "        )\n",
    " \n",
    "        # Step 3: Filter out tracks already liked by the user\n",
    "        liked_songs = sp.current_user_saved_tracks(limit=50)\n",
    "        liked_track_ids = {item['track']['id'] for item in liked_songs['items']}\n",
    " \n",
    "        filtered_recommendations = [track for track in recommendations['tracks'] if track['id'] not in liked_track_ids]\n",
    " \n",
    "        # Step 4: Return or store the recommendations\n",
    "        return {\"recommendations\": filtered_recommendations}\n",
    " \n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "    except SpotifyException as e:\n",
    "        if e.http_status == 429:\n",
    "            return JSONResponse(status_code=429, content={\"message\": \"Rate limit exceeded, please try again later.\"})\n",
    "        else:\n",
    "            return JSONResponse(status_code=500, content={\"message\": \"An error occurred while fetching recommendations.\"})\n",
    "\n",
    "# def format_recommendations(recommendations):\n",
    "#     formatted_list = []\n",
    "#     for rec in recommendations:\n",
    "#         description = rec[\"text\"]\n",
    "#         formatted_list.append(description)\n",
    "#     return formatted_list\n",
    "\n",
    "# def format_response(recommendations):\n",
    "#     response = \"Here are some songs we think you'll like:\\n\"\n",
    "    \n",
    "#     formatted_recommendations = format_recommendations(recommendations)\n",
    "#     response += \"\\n\".join(formatted_recommendations)\n",
    "    \n",
    "#     return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    async def start_server():\n",
    "        config = uvicorn.Config(app, host=\"127.0.0.1\", port=8235)\n",
    "        server = uvicorn.Server(config)\n",
    "        await server.serve()\n",
    "\n",
    "    await start_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = get_spotify_client()\n",
    "        \n",
    "        # Get the current user's ID as early as possible\n",
    "user_id = sp.current_user()['id']  # Get the current user's ID\n",
    "\n",
    "        # Get the text collection\n",
    "text_store = get_text_collection(user_id)\n",
    "        \n",
    "        # Replace with the actual collection name if it's different\n",
    "collection_name = f\"{user_id}_text_collection\"\n",
    "        \n",
    "        # Get the current number of songs in the collection\n",
    "curr_number_of_songs = text_store._collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(id=cd730745-3a8d-4c3a-a930-b6ddbab99e00, name=eqanbww3jh63cgf4ot5zyyr5d_text_collection)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_number_of_songs.peek()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
