{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Project: Song Recommendation System Based on User Mood\n",
    "This project aims to create a system that suggests songs based on a user's mood. We will use Spotify and Genius APIs to fetch user data, process this data to create embeddings using a pre-trained transformer model, store these embeddings in a FAISS index, and use LangChain and MLflow to manage the retrieval and generation processes.\n",
    " Step-by-Step Guide\n",
    " \n",
    " 1. Setup Environment and Install Dependencies\n",
    "**Why:** To ensure all necessary packages and tools are available for the project.\n",
    "**Action:** Install the required libraries such as `lyricsgenius`, `spotipy`, `transformers`, `scikit-learn`, `faiss-cpu`, `tqdm`, and `mlflow`.\n",
    "**Commands:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lyricsgenius\n",
    "%pip install spotipy\n",
    "%pip install spotipy lyricsgenius transformers scikit-learn gtts pydub librosa\n",
    "%pip install faiss-cpu\n",
    "%pip install tqdm\n",
    "%pip install torch\n",
    "%pip install lyricsgenius spotipy transformers scikit-learn gtts pydub librosa faiss-cpu tqdm mlflow\n",
    "%pip install torch  --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install uvicorn\n",
    "%pip install nest_asyncio\n",
    "%pip install chromadb\n",
    "%pip install -U FlagEmbedding\n",
    "%pip install langchain langchain-community\n",
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env export > environment.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for the project\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import lyricsgenius\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import logging\n",
    "import psutil  # For monitoring system memory\n",
    "import gc  # For managing memory through garbage collection\n",
    "import dotenv\n",
    "import tqdm as notebook_tqdm\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to monitor and log the flow of execution and potential issues\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from fastapi import FastAPI, HTTPException, Request\n",
    "from fastapi.responses import RedirectResponse\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "import lyricsgenius\n",
    "\n",
    "# TODO : limit the number of the request to the API\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Spotify OAuth configuration\n",
    "sp_oauth = SpotifyOAuth(\n",
    "    client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    "    redirect_uri=\"http://localhost:8235/callback\",  # Ensure this matches your registered Spotify redirect URI\n",
    "    scope=\"user-top-read user-library-read playlist-read-private\"\n",
    ")\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius(os.getenv(\"GENIUS_API_TOKEN\"))\n",
    "\n",
    "def get_spotify_client():\n",
    "    token_info = sp_oauth.get_cached_token()\n",
    "\n",
    "    if not token_info:\n",
    "        # No valid token, redirect to Spotify authorization\n",
    "        raise HTTPException(status_code=307, detail=\"Redirecting to Spotify authorization\", headers={\"Location\": \"/login\"})\n",
    "\n",
    "    access_token = token_info['access_token']\n",
    "    sp = spotipy.Spotify(auth=access_token)\n",
    "    return sp\n",
    "\n",
    "def get_audio_features_and_analysis(sp, track_id):\n",
    "    audio_features = sp.audio_features([track_id])[0]  # Fetching audio features\n",
    "    audio_analysis = sp.audio_analysis(track_id)       # Fetching audio analysis\n",
    "    return {\n",
    "        \"audio_features\": audio_features,\n",
    "        \"audio_analysis\": audio_analysis\n",
    "    }\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "    return {\"message\": \"Welcome to the Spotify integration with FastAPI\"}\n",
    "\n",
    "@app.get(\"/login\")\n",
    "async def login():\n",
    "    # Step 1: Redirect the user to Spotify's authorization page\n",
    "    auth_url = sp_oauth.get_authorize_url()\n",
    "    logger.info(f\"Redirecting to Spotify's authorization URL: {auth_url}\")\n",
    "    return RedirectResponse(auth_url)\n",
    "\n",
    "@app.get(\"/callback\")\n",
    "async def callback(request: Request):\n",
    "    # Step 2: Handle the redirect from Spotify and get the access token\n",
    "    code = request.query_params.get('code')\n",
    "    if not code:\n",
    "        raise HTTPException(status_code=400, detail=\"Missing authorization code\")\n",
    "\n",
    "    token_info = sp_oauth.get_access_token(code)\n",
    "\n",
    "    if token_info:\n",
    "        logger.info(\"Access token obtained successfully\")\n",
    "        # Redirect to a default page or the originally requested page\n",
    "        return RedirectResponse(url=\"/playlists\")\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Could not authenticate with Spotify\")\n",
    "\n",
    "@app.get(\"/playlists\")\n",
    "async def playlists():\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "        playlists = sp.current_user_playlists()\n",
    "        detailed_playlists = []\n",
    "\n",
    "        for playlist in playlists['items']:\n",
    "            playlist_data = {\n",
    "                \"name\": playlist['name'],\n",
    "                \"tracks\": []\n",
    "            }\n",
    "            tracks = sp.playlist_tracks(playlist['id'])\n",
    "            for track in tracks['items']:\n",
    "                track_info = {\n",
    "                    \"name\": track['track']['name'],\n",
    "                    \"album\": track['track']['album']['name'],\n",
    "                    \"artists\": [artist['name'] for artist in track['track']['artists']],\n",
    "                    \"url\": track['track']['external_urls']['spotify']\n",
    "                }\n",
    "                track_details = get_audio_features_and_analysis(sp, track['track']['id'])\n",
    "                track_info.update(track_details)\n",
    "                playlist_data['tracks'].append(track_info)\n",
    "            detailed_playlists.append(playlist_data)\n",
    "        \n",
    "        return {\"playlists\": detailed_playlists}\n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "\n",
    "@app.get(\"/liked_songs\")\n",
    "async def liked_songs():\n",
    "    try:\n",
    "        sp = get_spotify_client()\n",
    "        liked_songs = sp.current_user_saved_tracks()\n",
    "        detailed_songs = []\n",
    "\n",
    "        for item in liked_songs['items']:\n",
    "            track = item['track']\n",
    "            track_info = {\n",
    "                \"name\": track['name'],\n",
    "                \"album\": track['album']['name'],\n",
    "                \"artists\": [artist['name'] for artist in track['artists']],\n",
    "                \"url\": track['external_urls']['spotify']\n",
    "            }\n",
    "            track_details = get_audio_features_and_analysis(sp, track['id'])\n",
    "            track_info.update(track_details)\n",
    "            detailed_songs.append(track_info)\n",
    "        \n",
    "        return {\"liked_songs\": detailed_songs}\n",
    "    except HTTPException as e:\n",
    "        if e.status_code == 307:\n",
    "            return RedirectResponse(url=\"/login\")\n",
    "        raise e\n",
    "\n",
    "@app.get(\"/lyrics\")\n",
    "async def lyrics(artist: str, title: str):\n",
    "    try:\n",
    "        song = genius.search_song(title, artist)\n",
    "        if song:\n",
    "            return {\"lyrics\": song.lyrics}\n",
    "        else:\n",
    "            raise HTTPException(status_code=404, detail=\"Lyrics not found\")\n",
    "    except HTTPException as e:\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    logger.info(\"Starting FastAPI server...\")\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8235)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# we need to save the data first and then convert it to chroma format \n",
    "# might want to do as key being user then value being the stats of the data \n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "\n",
    "# TODO : add the user to the database\n",
    "# TODO : add the song embeddings to the database using the prev cell \n",
    "\n",
    "# sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "# sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "#                \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "# output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "# output_2 = model.encode(sentences_2, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "\n",
    "# print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][0]))\n",
    "# print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][1]))\n",
    "# # 0.7797\n",
    "# # 0.4620\n",
    "\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "# model we are using for mebedding as colbert vector \n",
    "\n",
    "#indexing model\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  use_fp16=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO UPDATE THE USER QUERY SAME AS THE WAY WE STORE IT \n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "def embed_user_query(user_input):\n",
    "    logger.info(\"Embedding user query using LangChain...\")\n",
    "    user_embedding = embeddings.embed_query(user_input)\n",
    "    logger.info(\"User query embedded.\")\n",
    "    user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "    print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "    return user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR ME FROM HERE ONWARD \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 5\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "\n",
    "def retrieve_lyrics_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "    docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "    return docs\n",
    "\n",
    "def retrieve_audio_features_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing audio feature retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=audio_index)\n",
    "    docs = retriever.similarity_search(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 audio features using LangChain.\")\n",
    "    return docs\n",
    "    \n",
    "def combine_retrieval_results(lyrics_docs, audio_docs):\n",
    "    logger.info(\"Combining retrieval results...\")\n",
    "    combined_results = lyrics_docs + audio_docs  # This could be a simple concatenation or more sophisticated merging\n",
    "    logger.info(f\"Combined {len(combined_results)} results.\")\n",
    "    return combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use the above in the cell w retrieve lyrics w langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6\n",
    "def format_recommendations(retrieved_docs):\n",
    "    logger.info(\"Formatting recommendations...\")\n",
    "    formatted_response = \"\\n\".join([f\"Song: {doc.metadata['title']} by {doc.metadata['artist']}\\n{doc.page_content[:100]}...\" for doc in retrieved_docs])\n",
    "    logger.info(\"Recommendations formatted.\")\n",
    "    return formatted_response\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the generation pipeline using an open-source model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "def generate_personalized_response(formatted_recommendations, user_query):\n",
    "    logger.info(\"Generating personalized response using LangChain...\")\n",
    "    response = generator(f\"Context: {formatted_recommendations}\\n\\nQuestion: {user_query}\\nAnswer:\", max_length=200, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve lyrics using the query embedding\n",
    "\n",
    "# Example user query\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
    "\n",
    "def embed_user_query(user_input):\n",
    "    logger.info(\"Embedding user query using LangChain...\")\n",
    "    user_embedding = embeddings.embed_query(user_input)\n",
    "    logger.info(\"User query embedded.\")\n",
    "    user_embedding = np.array(user_embedding) # Reshape to match FAISS input format\n",
    "    print(\"User embedding shape:\", user_embedding.shape)  # Debugging: print shape\n",
    "    return user_embedding\n",
    "\n",
    "\n",
    "user_query = \"summer happy vibes\"\n",
    "\n",
    "# Create an embedding for the user query\n",
    "query_embedding = embed_user_query(user_query)\n",
    "\n",
    "# Check if the embedding shape matches what FAISS expects (should be 2D, with one row per item)\n",
    "print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "\n",
    "def retrieve_songs(query):\n",
    "    # Preprocess the query to get embeddings\n",
    "    query_embedding = preprocess_query(query)\n",
    "    \n",
    "    # Search the FAISS indices\n",
    "    lyrics_distances, lyrics_indices = lyrics_index.search(query_embedding, k=5)\n",
    "    lyrics_results = [lyrics_data[idx] for idx in lyrics_indices[0]]\n",
    "    \n",
    "    audio_distances, audio_indices = audio_index.search(query_embedding, k=5)\n",
    "    audio_results = [tracks[idx] for idx in audio_indices[0]]\n",
    "    \n",
    "    # Combine and rank results\n",
    "    combined_results = merge_and_rank_results(lyrics_results, audio_results)\n",
    "    return combined_results\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_lyrics_with_langchain(query_embedding):\n",
    "    logger.info(\"Performing lyrics retrieval using LangChain...\")\n",
    "    retriever = FAISS(embedding_function=embeddings.embed_query, index=lyrics_index, docstore=InMemoryDocstore(lyrics_data), index_to_docstore_id={})\n",
    "    docs = retriever.similarity_search_by_vector(query_embedding, k=5)\n",
    "    logger.info(f\"Retrieved top 5 lyrics using LangChain.\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "lyrics_docs = retrieve_lyrics_with_langchain(query_embedding)\n",
    "\n",
    "# Check the results\n",
    "print(\"Lyrics retrieval results:\")\n",
    "for doc in lyrics_docs:\n",
    "    print(doc.metadata['title'], doc.metadata['artist'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
